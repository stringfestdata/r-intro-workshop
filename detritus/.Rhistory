"http://www.youtube.com/watch?v=kseBA178jNc",
"http://www.youtube.com/watch?v=a7E29H5ZUmE",
"http://www.youtube.com/watch?v=yET750M1Kas",
"http://www.youtube.com/watch?v=uLFqhQWEn00",
"http://www.youtube.com/watch?v=6AUjC-5jQmc",
"http://www.youtube.com/watch?v=UhV9VBA0A_g",
"http://www.youtube.com/watch?v=D0ZUFLJLj58",
"http://www.youtube.com/watch?v=h8Bjwxb3_k4",
"http://www.youtube.com/watch?v=uUMOMkiwo-Q",
"http://www.youtube.com/watch?v=UImC8p8GFZM",
"http://www.youtube.com/watch?v=aOQdxhLCuCA",
"http://www.youtube.com/watch?v=tLjnMNPddC4",
"http://www.youtube.com/watch?v=f2Mz_gPT4oE",
"http://www.youtube.com/watch?v=Tnw77rpm-BQ",
"http://www.youtube.com/watch?v=II0oqgUkwxA",
"http://www.youtube.com/watch?v=M8MthJEVBR0",
"http://www.youtube.com/watch?v=PPnNeoFfEPA",
"http://www.youtube.com/watch?v=ogDdF6fLCx4",
"http://www.youtube.com/watch?v=6NEZnkyaHQs",
"http://www.youtube.com/watch?v=e-CFYi52gpc",
"http://www.youtube.com/watch?v=9W2mlLgfwwA",
"http://www.youtube.com/watch?v=f83kcI3HSXo",
"http://www.youtube.com/watch?v=4M5VinpEBmg",
"http://www.youtube.com/watch?v=okJxIOwYEOM",
"http://www.youtube.com/watch?v=j8nX9IdCRLg",
"http://www.youtube.com/watch?v=GTt_nKU0HJo",
"http://www.youtube.com/watch?v=nBOJ0wynrGg",
"http://www.youtube.com/watch?v=90QdbiUTq7k",
"http://www.youtube.com/watch?v=HSqKnEiByTQ",
"http://www.youtube.com/watch?v=VeS0fh8xUVA",
"http://www.youtube.com/watch?v=DOHBgfCwEYk",
"http://www.youtube.com/watch?v=lPSn5Cscxwk",
"http://www.youtube.com/watch?v=PzshpJbc8CE",
"http://www.youtube.com/watch?v=-rsf7-NXWtI",
"http://www.youtube.com/watch?v=BYDbE3PuOvM",
"http://www.youtube.com/watch?v=udvUokbj3Js",
"http://www.youtube.com/watch?v=KWa7snKsLz0",
"http://www.youtube.com/watch?v=YuoEegbrW1I",
"http://www.youtube.com/watch?v=KLQqGtYydUc",
"http://www.youtube.com/watch?v=fsdci-Uf1zw",
"http://www.youtube.com/watch?v=HYEOvkLSY-0",
"http://www.youtube.com/watch?v=CDrvvlKD-HI",
"http://www.youtube.com/watch?v=yYKBf-rCn_M",
"http://www.youtube.com/watch?v=9qGI0hQqUn4",
"http://www.youtube.com/watch?v=W_yBhTer9Do",
"http://www.youtube.com/watch?v=_csX8sCzJd0",
"http://www.youtube.com/watch?v=SexKsU4qDqM",
"http://www.youtube.com/watch?v=dk7-Ana8qZc",
"http://www.youtube.com/watch?v=eHU-5ljzvuk",
"http://www.youtube.com/watch?v=jVkWDZ7B-Zs",
"http://www.youtube.com/watch?v=NHk-g_EChik",
"http://www.youtube.com/watch?v=hYPwX_CfYv4",
"http://www.youtube.com/watch?v=iW6KXGaqWU8",
"http://www.youtube.com/watch?v=Jzt-I4mt8sQ",
"http://www.youtube.com/watch?v=qE09ZtiaZl4",
"http://www.youtube.com/watch?v=LSjrrDRF0q0",
"http://www.youtube.com/watch?v=bPvJg_faYXg",
"http://www.youtube.com/watch?v=ohGFPF12Qwc",
"http://www.youtube.com/watch?v=NJEvr5ZoEEw",
"http://www.youtube.com/watch?v=0WBgD0l5r-4",
"http://www.youtube.com/watch?v=hnZr3xL3ky4",
"http://www.youtube.com/watch?v=5anm6AmVrvM",
"http://www.youtube.com/watch?v=uCo-ypA-G70",
"http://www.youtube.com/watch?v=EPhEvzbYXec",
"http://www.youtube.com/watch?v=LSDQGWdgNJs",
"http://www.youtube.com/watch?v=sCLTjucgHvQ",
"http://www.youtube.com/watch?v=0ofxeA47gns",
"http://www.youtube.com/watch?v=3mCPWvFJTRc",
"http://www.youtube.com/watch?v=aijXoglf8wo",
"http://www.youtube.com/watch?v=qyqyT6qcHLc",
"http://www.youtube.com/watch?v=gKPcAJTgDXQ",
"http://www.youtube.com/watch?v=eilE4qFATrk",
"http://www.youtube.com/watch?v=zjnFKS9iXPs",
"http://www.youtube.com/watch?v=0YxuHMatJVI",
"http://www.youtube.com/watch?v=JfuFGMfgvfY",
"http://www.youtube.com/watch?v=KqIMWTnkUiU",
"http://www.youtube.com/watch?v=BDoAWz89z74",
"http://www.youtube.com/watch?v=pMQK1Zcc9jw",
"http://www.youtube.com/watch?v=HPDG_KXiLBo",
"http://www.youtube.com/watch?v=jr2F-mrE1Uc",
"http://www.youtube.com/watch?v=2xE6FUp7guQ",
"http://www.youtube.com/watch?v=uylH1MQM5uw",
"http://www.youtube.com/watch?v=QogBqCx_EgY",
"http://www.youtube.com/watch?v=qTAppd6KsNs",
"http://www.youtube.com/watch?v=mmNO1QPUFrU",
"http://www.youtube.com/watch?v=ldoQws7Zbx8"
))
#Read a list of links from a CSV file with a column named url with all the URLS to mine
#youtube_list = read.csv("FoA_Links.csv", header = TRUE, sep = ";")
#Setting up empty df to store data
temp.df = data.frame(id="", date="", title="", duration="", mins="", secs="",
description="", views= "", pos="", neg="", fullurl="")
youtube.df = data.frame() #Will include the final outcome
#Loop through the list of links and extract some general metadata
for(i in 1:length(youtube_list$url)){
youtube_url = read_html(as.character(youtube_list$url[[i]]))
id = as.character(html_nodes(youtube_url, 'meta[itemprop="videoId"]') %>%
html_attr("content"))
date = as.character(html_nodes(youtube_url, 'meta[itemprop="datePublished"]') %>%
html_attr("content"))
title = as.character(html_nodes(youtube_url, 'meta[itemprop="name"]') %>%
html_attr("content"))
mins = as.numeric(gsub("M","",str_extract(as.character(html_nodes(youtube_url, 'meta[itemprop="duration"]') %>%
html_attr("content")), "\\d*M")))
secs = as.numeric(gsub("S","",str_extract(as.character(html_nodes(youtube_url, 'meta[itemprop="duration"]') %>%
html_attr("content")), "\\d*S")))
duration = (mins*60) + secs
description = as.character(html_node(youtube_url, '#eow-description') %>%
html_text())
views = as.numeric(html_nodes(youtube_url, 'meta[itemprop="interactionCount"]') %>%
html_attr("content"))
try({
pos = html_nodes(youtube_url, 'span.yt-uix-button-content') %>%
html_text()
pos = as.numeric(gsub(",", "", pos[15]))}, silent = TRUE)
if(length(pos)==0){
pos=NA
}
try({
neg = html_nodes(youtube_url, 'span.yt-uix-button-content') %>%
html_text()
neg = as.numeric(gsub(",", "", neg[18]))}, silent = TRUE)
if(length(neg)==0){
neg=NA
}
fullurl = paste("https://www.youtube.com/watch?v=",id, sep="")
#Saves output into a df and appends the data to the final df
temp.df = data.frame(id, date, title, duration, description, mins, secs, views, pos, neg, fullurl)
youtube.df = rbind(youtube.df, temp.df)
#Empties all the fields before creating a new entry
temp.df = data.frame(id="", date="", title="", duration="", mins="", secs="", description="",
views= "", pos="", neg="", fullurl="")
#Clear all temp variables
remove(id, date, title, duration, description,views, pos, neg, fullurl, mins, secs)
}
temp.df
#Delete temporary df
remove(temp.df, youtube_url, i, youtube_list)
head(youtube.df,3)
write.csv(youtube.df,"C:/RFiles/Youtube.csv")
library(rvest)
library(stringr)
## Manually build a list of videos
youtube_list = data.frame(url=c("http://www.youtube.com/watch?v=sGw6r5GVA5g",
"http://www.youtube.com/watch?v=d07yuwGHZpo",
"http://www.youtube.com/watch?v=HE9CIbetNnI",
"http://www.youtube.com/watch?v=-c2QvyPpkAM",
"http://www.youtube.com/watch?v=deKxQwtd4-U",
"http://www.youtube.com/watch?v=qvxmHbrwYmk",
"http://www.youtube.com/watch?v=JyWrLH7monI",
"http://www.youtube.com/watch?v=EsuDf8AsOXc",
"http://www.youtube.com/watch?v=wGauctajWPQ",
"http://www.youtube.com/watch?v=4KtkknL6rXs",
"http://www.youtube.com/watch?v=cvPbFwKkJBA",
"http://www.youtube.com/watch?v=bd0waWRKRes",
"http://www.youtube.com/watch?v=SidxAJ1MRFo",
"http://www.youtube.com/watch?v=7RVGdA9AhrY",
"http://www.youtube.com/watch?v=fWyw4DJCSsE",
"http://www.youtube.com/watch?v=4ynjc4rFR0c",
"http://www.youtube.com/watch?v=zih2mUAfCGY",
"http://www.youtube.com/watch?v=A9vzpR0BOXc",
"http://www.youtube.com/watch?v=dND4coLI_B8",
"http://www.youtube.com/watch?v=7Ugoj7hpUEA",
"http://www.youtube.com/watch?v=zHJPliWS9FQ",
"http://www.youtube.com/watch?v=c8reU-H1PKQ",
"http://www.youtube.com/watch?v=CzP8nO9UVvY",
"http://www.youtube.com/watch?v=NvGv1n4TW28",
"http://www.youtube.com/watch?v=RWinxxyVDUc",
"http://www.youtube.com/watch?v=Yoh3tdyZ-3M",
"http://www.youtube.com/watch?v=ZHjog9PzyPM",
"http://www.youtube.com/watch?v=utmBcFp-FQI",
"http://www.youtube.com/watch?v=R2nlDu-2E4o",
"http://www.youtube.com/watch?v=0EXdPcbsTZI",
"http://www.youtube.com/watch?v=h9FTX7TgkpM",
"http://www.youtube.com/watch?v=MjbmsVDnAL0",
"http://www.youtube.com/watch?v=d8cfrdUjcuw",
"http://www.youtube.com/watch?v=3BI_IDXOAMg",
"http://www.youtube.com/watch?v=pI2px2KoapU",
"http://www.youtube.com/watch?v=z7gUwuOxZAY",
"http://www.youtube.com/watch?v=5pXbaVJIqec",
"http://www.youtube.com/watch?v=fvnIRr30Mus",
"http://www.youtube.com/watch?v=p_IhfObVc6A",
"http://www.youtube.com/watch?v=buRwtzVw7UQ",
"http://www.youtube.com/watch?v=_gl1z2KWqXY",
"http://www.youtube.com/watch?v=KZgOwmS3iFY",
"http://www.youtube.com/watch?v=9LfI7eKJbAI",
"http://www.youtube.com/watch?v=JF1ZLOczSvw",
"http://www.youtube.com/watch?v=rmTN-nFaeOM",
"http://www.youtube.com/watch?v=v_Mv2f9GZ5M",
"http://www.youtube.com/watch?v=agQAda7HphQ",
"http://www.youtube.com/watch?v=9GjUwItfO2Y",
"http://www.youtube.com/watch?v=ZrPEAljQjRM",
"http://www.youtube.com/watch?v=rZScXs8tfFM",
"http://www.youtube.com/watch?v=E_e4bZDdygQ",
"http://www.youtube.com/watch?v=8fBUUSrmsP4",
"http://www.youtube.com/watch?v=Bsfe-2VcvZg",
"http://www.youtube.com/watch?v=GK7ifXM3alI",
"http://www.youtube.com/watch?v=AD2nkTGkO4E",
"http://www.youtube.com/watch?v=DlqKfYTgc9Q",
"http://www.youtube.com/watch?v=dShR33CdlY8",
"http://www.youtube.com/watch?v=bBAdhclCT9g",
"http://www.youtube.com/watch?v=Ix-604DN1dA",
"http://www.youtube.com/watch?v=XUihoGc-h4M",
"http://www.youtube.com/watch?v=f8s-jY9y220",
"http://www.youtube.com/watch?v=iGo1dDoTeC8",
"http://www.youtube.com/watch?v=6er1HGHFf5M",
"http://www.youtube.com/watch?v=KHO5NIcZAc4",
"http://www.youtube.com/watch?v=Mx7a-uj2sZI",
"http://www.youtube.com/watch?v=6ZIFNAV1rOQ",
"http://www.youtube.com/watch?v=MzydF6KOGy8",
"http://www.youtube.com/watch?v=JPezrWwvsJM",
"http://www.youtube.com/watch?v=t57uDi2jDbc",
"http://www.youtube.com/watch?v=SaQfOIeOuHk",
"http://www.youtube.com/watch?v=N1mADWqzWy4",
"http://www.youtube.com/watch?v=XjpUF6FGgNI",
"http://www.youtube.com/watch?v=M3OE7Z62oGM",
"http://www.youtube.com/watch?v=AlgB6hADI5Q",
"http://www.youtube.com/watch?v=xiqjiI_Pff4",
"http://www.youtube.com/watch?v=y9hnnfjTxUA",
"http://www.youtube.com/watch?v=_ZVSV9Y7TGw"
))
#Read a list of links from a CSV file with a column named url with all the URLS to mine
#youtube_list = read.csv("FoA_Links.csv", header = TRUE, sep = ";")
#Setting up empty df to store data
temp.df = data.frame(id="", date="", title="", duration="", mins="", secs="",
description="", views= "", pos="", neg="", fullurl="")
youtube.df = data.frame() #Will include the final outcome
#Loop through the list of links and extract some general metadata
for(i in 1:length(youtube_list$url)){
youtube_url = read_html(as.character(youtube_list$url[[i]]))
id = as.character(html_nodes(youtube_url, 'meta[itemprop="videoId"]') %>%
html_attr("content"))
date = as.character(html_nodes(youtube_url, 'meta[itemprop="datePublished"]') %>%
html_attr("content"))
title = as.character(html_nodes(youtube_url, 'meta[itemprop="name"]') %>%
html_attr("content"))
mins = as.numeric(gsub("M","",str_extract(as.character(html_nodes(youtube_url, 'meta[itemprop="duration"]') %>%
html_attr("content")), "\\d*M")))
secs = as.numeric(gsub("S","",str_extract(as.character(html_nodes(youtube_url, 'meta[itemprop="duration"]') %>%
html_attr("content")), "\\d*S")))
duration = (mins*60) + secs
description = as.character(html_node(youtube_url, '#eow-description') %>%
html_text())
views = as.numeric(html_nodes(youtube_url, 'meta[itemprop="interactionCount"]') %>%
html_attr("content"))
try({
pos = html_nodes(youtube_url, 'span.yt-uix-button-content') %>%
html_text()
pos = as.numeric(gsub(",", "", pos[15]))}, silent = TRUE)
if(length(pos)==0){
pos=NA
}
try({
neg = html_nodes(youtube_url, 'span.yt-uix-button-content') %>%
html_text()
neg = as.numeric(gsub(",", "", neg[18]))}, silent = TRUE)
if(length(neg)==0){
neg=NA
}
fullurl = paste("https://www.youtube.com/watch?v=",id, sep="")
#Saves output into a df and appends the data to the final df
temp.df = data.frame(id, date, title, duration, description, mins, secs, views, pos, neg, fullurl)
youtube.df = rbind(youtube.df, temp.df)
#Empties all the fields before creating a new entry
temp.df = data.frame(id="", date="", title="", duration="", mins="", secs="", description="",
views= "", pos="", neg="", fullurl="")
#Clear all temp variables
remove(id, date, title, duration, description,views, pos, neg, fullurl, mins, secs)
}
temp.df
#Delete temporary df
remove(temp.df, youtube_url, i, youtube_list)
head(youtube.df,3)
write.csv(youtube.df,"C:/RFiles/Youtube2.csv")
library(twitteR)
library(ROAuth)
#https://stackoverflow.com/questions/25856394/r-twitter-package-authorization-error
api_key <- "gjpaoCYaJgdvQvPPvowET9kOH"
api_secret <- "qehrtXirRuq7S5qD6v5uxMRuSYB3jQzP5ydEecq7FGIZSRltL2"
access_token <- "952735400363286528-PjkOKGfQfbTXKK3bmQMkAeg88NbxCF0"
access_token_secret <- "qDQPzdXEOueocMFgVuLUwMQ0fP9IXiyqwfUOtEdN0bIt5"
setup_twitter_oauth(api_key,api_secret,access_token,access_token_secret)
#get one tweet
totweet<-quotes[sample(nrow(quotes),1),]
totweet
library(twitteR)
library(ROAuth)
api_key <- "gjpaoCYaJgdvQvPPvowET9kOH"
api_secret <- "qehrtXirRuq7S5qD6v5uxMRuSYB3jQzP5ydEecq7FGIZSRltL2"
access_token <- "952735400363286528-PjkOKGfQfbTXKK3bmQMkAeg88NbxCF0"
access_token_secret <- "qDQPzdXEOueocMFgVuLUwMQ0fP9IXiyqwfUOtEdN0bIt5"
setup_twitter_oauth(api_key,api_secret,access_token,access_token_secret)
quotes<-read.csv("C:/ExcelBot/Excelbot.csv")
#convert factor to chracter
quotes[]<-lapply(quotes,as.character)
#get one tweet
totweet<-quotes[sample(nrow(quotes),1),]
totweet
totweet<-quotes[sample(nrow(quotes),1),]
totweet
totweet<-quotes[sample(nrow(quotes),1),]
totweet
totweet<-quotes[sample(nrow(quotes),1),]
totweet
totweet<-quotes[sample(nrow(quotes),1),]
totweet
totweet<-quotes[sample(nrow(quotes),1),]
totweet
totweet<-quotes[sample(nrow(quotes),1),]
totweet
totweet<-quotes[sample(nrow(quotes),1),]
totweet
totweet<-quotes[sample(nrow(quotes),1),]
totweet
totweet<-quotes[sample(nrow(quotes),1),]
totweet
totweet<-quotes[sample(nrow(quotes),1),]
totweet
totweet<-quotes[sample(nrow(quotes),1),]
totweet
totweet<-quotes[sample(nrow(quotes),1),]
totweet
totweet<-quotes[sample(nrow(quotes),1),]
totweet
totweet<-quotes[sample(nrow(quotes),1),]
totweet
totweet<-quotes[sample(nrow(quotes),1),]
totweet
totweet<-quotes[sample(nrow(quotes),1),]
totweet
totweet<-quotes[sample(nrow(quotes),1),]
totweet
totweet<-quotes[sample(nrow(quotes),1),]
totweet
totweet<-quotes[sample(nrow(quotes),1),]
totweet
tweet(totweet, bypassCharLimit=TRUE)
class(mtcars)
length(mtcars)
dim(mtcars)
data()
class(EuStockMarkets)
class(LakeHuron)
class(Titanic)
class(airmiles)
class(precip)
is.vector(precip)
length(precip)
View(precip)
class(precip)
library(stats)
summary(mtcars)
names(log)
names(iris)
dplyr::select(iris, Species)
names(brandquakl)
names(brandqual)
brandqual <- read.csv("https://assets.datacamp.com/production/repositories/4494/datasets/ef8b84314a5cf249c02577f29e0897c6c61f9f5d/brandquality02072019.csv")
names(brandqual)
library(dplyr)
names(brandqual)
brandqual9 <- select(brandqual, trendy:innovator)
cor.test(brandqual9)
brandqual9 <- select(brandqual, trendy:innovator)
cor.test(brandqual9)
?cor.test
brandqual9 <- select(brandqual, trendy:innovator)
library(Hmisc)
rcorr(brandqual9)
data("mtcars")
my_data <- mtcars[, c(1,3,4,5,6,7)]
rcorr(as.matrix(brandqual9))
cor(brandqual9)
cor.test(matrix(brandqual9))
cor.test(as.matrix(brandqual9))
rcorr(as.matrix(brandqual9))
# view item correlations
brandqualcor <- cor(brandqual9)
# visualize significance of item correlations
rcorr(as.matrix(brandqual9))
# visualize significance of item correlations
rcorr(brandqualcor)
# view item correlations
brandqualcor <- cor(brandqual9)
# visualize significance of item correlations
rcorr(brandqualcor)
brandqual <- read.csv("https://assets.datacamp.com/production/repositories/4494/datasets/ef8b84314a5cf249c02577f29e0897c6c61f9f5d/brandquality02072019.csv")
names(brandqual)
brandqual9 <- select(brandqual, trendy:innovator)
# view item correlations
brandqualcor <- cor(brandqual9)
# visualize significance of item correlations
rcorr(brandqualcor)
library(psych)
describe(iris)
brandrep[is.na(brandrep)]
library(psych)
brandqual <- read.csv("https://assets.datacamp.com/production/repositories/4494/datasets/4ec2577fcb719529ee5b85b93ada91ad2b5d6f4e/brandquality02122019.csv")
# summary statistics
describe(brandqual)
# set illogical values to NA
brandqual[brandqual > 5] <- NA
# how many missing cases do we have?
sum(!complete.cases(brandqual))
# how many missing cases do we have?
sum(complete.cases(brandqual))
sum(is.na(brandqual))
brandqual <- read.csv("https://assets.datacamp.com/production/repositories/4494/datasets/4ec2577fcb719529ee5b85b93ada91ad2b5d6f4e/brandquality02122019.csv")
# summary statistics
describe(brandqual)
# set illogical values to NA
brandqual[brandqual$innovator > 5] <- NA
# set illogical values to NA
brandqual$innovator > 5 <- NA
# summary statistics
describe(brandqual)
# set illogical values to NA
brandqual[brandqual$innovator > 5] <- NA
# set illogical values to NA
brandqual$innovator > 5 <- NA
# set illogical values to NA
brandqual$innovator > 5
# set illogical values to NA
brandqual[brandqual$innovator] > 5 <- NA
# set illogical values to NA
brandqual[brandqual$innovator > 5]  <- NA
library(tidyr)
replace_na(brandqual$innovator > 5)
brandqual$innovator <- replace_na(brandqual$innovator > 5)
describe(brandqual)
brandqual <- read.csv("https://assets.datacamp.com/production/repositories/4494/datasets/4ec2577fcb719529ee5b85b93ada91ad2b5d6f4e/brandquality02122019.csv")
describe(brandqual)
library(tidyr)
brandqual$innovator <- replace_na(brandqual$innovator > 5)
# how many missing cases do we have?
sum(complete.cases(brandqual))
# how many missing cases do we have?
sum(!complete.cases(brandqual))
# drop missing values
brandqual <- na.omit(brandqual)
# re-describe dataset
describe(brandqual)
brandqual <- read.csv("https://assets.datacamp.com/production/repositories/4494/datasets/4ec2577fcb719529ee5b85b93ada91ad2b5d6f4e/brandquality02122019.csv")
describe(brandqual)
library(tidyr)
brandqual$innovator <- replace_na(brandqual$innovator > 5)
# how many missing cases do we have?
sum(!complete.cases(brandqual))
# drop missing values
brandqual <- na.omit(brandqual)
# re-describe dataset
describe(brandqual)
describe(brandqual)
library(tidyr)
replace_na(brandqual$innovator > 5)
brandqual <- read.csv("https://assets.datacamp.com/production/repositories/4494/datasets/4ec2577fcb719529ee5b85b93ada91ad2b5d6f4e/brandquality02122019.csv")
describe(brandqual)
library(tidyr)
replace_na(x, list(a=0, b=0))
replace_na(brandqual, list(innovator > 5))
replace_na(brandqual, list(brandqual$innovator > 5))
replace_with_na_all(data = brandqual,
condition = ~.innovator > 5)
replace_with_na_all(data = brandqual,
condition = ~.innovator > 5)
library(naniar)
install.packages("naniar")
library(naniar)
replace_with_na_all(data = brandqual,
condition = ~.innovator > 5)
replace_with_na_all(data = brandqual,
condition = ~.brandqual$innovator > 5)
replace_with_na_all(data = brandqual,
condition = ~.brandqual$innovator > 5)
replace_with_na_all(data = brandqual,
condition = ~innovator > 5)
replace_with_na_all(data = brandqual,
condition = ~brandqual$innovator > 5)
replace_with_na_all(data = brandqual,
condition = .innovator > 5)
replace_with_na_all(data = brandqual,
condition = ~.innovator > 5)
replace_with_na_all(data = brandqual,
condition = ~.innovator > 5)
brandqual <- replace_with_na(brandqual, replace = list(innovator > 5))
brandqual <- replace_with_na(brandqual, replace = list(brandqual$innovator > 5))
brandqual <- replace_with_na(brandqual, replace = list(brandqual$innovator > 5))
library(naniar)
describe(brandqual)
brandqual <- read.csv("https://assets.datacamp.com/production/repositories/4494/datasets/4ec2577fcb719529ee5b85b93ada91ad2b5d6f4e/brandquality02122019.csv")
library(naniar)
library(tidyr)
describe(brandqual)
brandqual <- replace_with_na(brandqual, replace = list(brandqual$innovator > 5))
# how many missing cases do we have?
sum(!complete.cases(brandqual))
# drop missing values
brandqual <- na.omit(brandqual)
# re-describe dataset
describe(brandqual)
library(naniar)
library(tidyr)
describe(brandqual)
brandqual <- replace_with_na(brandqual, replace = list(brandqual$innovator > 5))
describe(brandqual)
brandqual <- replace_with_na(brandqual, replace = = brandqual$innovator > 5)
brandqual <- replace_with_na(brandqual, replace = brandqual$innovator > 5)
brandqual <- replace_with_na(brandqual, replace = list(brandqual$innovator > 5))
brandqual %>%  replace_with_na(replace = list(brandqual$innovator > 5))
describe(brandqual)
brandqual %>%  replace_with_na(replace = list(brandqual$innovator == 11))
describe(brandqual)
